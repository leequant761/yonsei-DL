{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27744,
     "status": "ok",
     "timestamp": 1575468377099,
     "user": {
      "displayName": "JaeHyun Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA1pE8sVsuuLMGC6ajwh6T9omE5mslxbxmoUVUX=s64",
      "userId": "15717303300889025519"
     },
     "user_tz": -540
    },
    "id": "-gA8GZgHLokd",
    "outputId": "4b7bbc23-f682-4bc1-a58a-1d93a4f6239e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYIXzcp3KK4n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_NdXBi9KBCn"
   },
   "outputs": [],
   "source": [
    "# original location\n",
    "data_dir = \"/gdrive/My Drive/Colab Notebooks/DL/\" + 'data/train/images'\n",
    "# destination\n",
    "dest_dir = \"/gdrive/My Drive/Colab Notebooks/DL/\" + 'data/splited'\n",
    "\n",
    "# split data train/valid/test\n",
    "train_dir = os.path.join(dest_dir, 'train')\n",
    "validation_dir = os.path.join(dest_dir, 'valid')\n",
    "test_dir = os.path.join(dest_dir, 'test')\n",
    "\n",
    "train_Cargo_dir = os.path.join(train_dir, 'Cargo')\n",
    "train_Military_dir = os.path.join(train_dir, 'Military')\n",
    "train_Carrier_dir = os.path.join(train_dir, 'Carrier')\n",
    "train_Cruise_dir = os.path.join(train_dir, 'Cruise')\n",
    "train_Tankers_dir = os.path.join(train_dir, 'Tanker')\n",
    "\n",
    "validation_Cargo_dir = os.path.join(validation_dir, 'Cargo')\n",
    "validation_Military_dir = os.path.join(validation_dir, 'Military')\n",
    "validation_Carrier_dir = os.path.join(validation_dir, 'Carrier')\n",
    "validation_Cruise_dir = os.path.join(validation_dir, 'Cruise')\n",
    "validation_Tankers_dir = os.path.join(validation_dir, 'Tanker')\n",
    "\n",
    "test_Cargo_dir = os.path.join(test_dir, 'Cargo')\n",
    "test_Military_dir = os.path.join(test_dir, 'Military')\n",
    "test_Carrier_dir = os.path.join(test_dir, 'Carrier')\n",
    "test_Cruise_dir = os.path.join(test_dir, 'Cruise')\n",
    "test_Tankers_dir = os.path.join(test_dir, 'Tanker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2366,
     "status": "ok",
     "timestamp": 1575468383423,
     "user": {
      "displayName": "JaeHyun Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA1pE8sVsuuLMGC6ajwh6T9omE5mslxbxmoUVUX=s64",
      "userId": "15717303300889025519"
     },
     "user_tz": -540
    },
    "id": "uDrm6nKvM3xF",
    "outputId": "6ba20a28-e6cc-42d7-9410-6eb1ebb6b0ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2120\n",
       "2    1167\n",
       "3     916\n",
       "4     832\n",
       "5    1217\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = pd.read_csv(\"/gdrive/My Drive/Colab Notebooks/DL/\" + 'data/train/train.csv')\n",
    "label_list.category.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xei9OI8BKBCt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJmoO-pzKBCv"
   },
   "outputs": [],
   "source": [
    "fname_dir = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2cqtNQhKBC0"
   },
   "outputs": [],
   "source": [
    "cargo_fname = label_list.loc[label_list.category==1,:].image.values\n",
    "fname_dir['Cargo_train'], fname_dir['Cargo_test'] = train_test_split(cargo_fname, test_size=0.25, random_state=2067)\n",
    "fname_dir['Cargo_train'], fname_dir['Cargo_valid'] = train_test_split(fname_dir['Cargo_train'], test_size=0.25, random_state=2067)\n",
    "\n",
    "military_fname = label_list.loc[label_list.category==2,:].image.values\n",
    "fname_dir['Military_train'], fname_dir['Military_test'] = train_test_split(military_fname, test_size=0.25, random_state=2067)\n",
    "fname_dir['Military_train'], fname_dir['Military_valid'] = train_test_split(fname_dir['Military_train'], test_size=0.25, random_state=2067)\n",
    "\n",
    "carrier_fname = label_list.loc[label_list.category==3,:].image.values\n",
    "fname_dir['Carrier_train'], fname_dir['Carrier_test'] = train_test_split(carrier_fname, test_size=0.25, random_state=2067)\n",
    "fname_dir['Carrier_train'], fname_dir['Carrier_valid'] = train_test_split(fname_dir['Carrier_train'], test_size=0.25, random_state=2067)\n",
    "\n",
    "cruise_fname = label_list.loc[label_list.category==4,:].image.values\n",
    "fname_dir['Cruise_train'], fname_dir['Cruise_test'] = train_test_split(cruise_fname, test_size=0.25, random_state=2067)\n",
    "fname_dir['Cruise_train'], fname_dir['Cruise_valid'] = train_test_split(fname_dir['Cruise_train'], test_size=0.25, random_state=2067)\n",
    "\n",
    "tanker_fname = label_list.loc[label_list.category==5,:].image.values\n",
    "fname_dir['Tanker_train'], fname_dir['Tanker_test'] = train_test_split(tanker_fname, test_size=0.25, random_state=2067)\n",
    "fname_dir['Tanker_train'], fname_dir['Tanker_valid'] = train_test_split(fname_dir['Tanker_train'], test_size=0.25, random_state=2067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2290,
     "status": "ok",
     "timestamp": 1575468386914,
     "user": {
      "displayName": "JaeHyun Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA1pE8sVsuuLMGC6ajwh6T9omE5mslxbxmoUVUX=s64",
      "userId": "15717303300889025519"
     },
     "user_tz": -540
    },
    "id": "J7O7NSkbKBC2",
    "outputId": "ed172d55-25a2-42da-c383-4c7aa6d251bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n",
      "already exist\n"
     ]
    }
   ],
   "source": [
    "# data/splited\n",
    "try:\n",
    "    os.mkdir(dest_dir)\n",
    "except FileExistsError:\n",
    "    print('already exist')\n",
    "\n",
    "try:\n",
    "    os.mkdir(train_dir)\n",
    "except FileExistsError:\n",
    "    print('already exist')\n",
    "    \n",
    "try:\n",
    "    os.mkdir(validation_dir)\n",
    "except FileExistsError:\n",
    "    print('already exist')\n",
    "    \n",
    "try:\n",
    "    os.mkdir(test_dir)\n",
    "except FileExistsError:\n",
    "    print('already exist')\n",
    "    \n",
    "# data/splited/train/...\n",
    "# data/splited/valid/...\n",
    "# data/splited/test/...    \n",
    "mkdir_list = [train_Cargo_dir,train_Military_dir ,train_Carrier_dir ,train_Cruise_dir ,train_Tankers_dir ,\n",
    "              validation_Cargo_dir ,validation_Military_dir ,validation_Carrier_dir ,validation_Cruise_dir ,\n",
    "              validation_Tankers_dir ,test_Cargo_dir ,test_Military_dir ,test_Carrier_dir ,test_Cruise_dir ,test_Tankers_dir]\n",
    "\n",
    "for mkdir in mkdir_list:\n",
    "    try:\n",
    "        os.mkdir(mkdir)\n",
    "        for fname in fname_dir[mkdir.split('\\\\')[-1] + '_' + mkdir.split('\\\\')[-2]]:\n",
    "            src = os.path.join(data_dir, fname)\n",
    "            dst = os.path.join(mkdir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "    except FileExistsError:\n",
    "        print('already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12451,
     "status": "ok",
     "timestamp": 1575468397241,
     "user": {
      "displayName": "JaeHyun Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA1pE8sVsuuLMGC6ajwh6T9omE5mslxbxmoUVUX=s64",
      "userId": "15717303300889025519"
     },
     "user_tz": -540
    },
    "id": "9JNzzCHoKBC5",
    "outputId": "979e383b-3cf1-46a2-945e-9e7628c3ef8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3515 images belonging to 5 classes.\n",
      "Found 1173 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=64, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150, 150), batch_size=64, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWgxJhCaKBC7"
   },
   "source": [
    "마지막 1개의 layer만 finetuning을 해보자. (batchnormalization의 **hyperparamter도 포함**하여)\n",
    "\n",
    "왜냐면 초기 층은 generic하고 reusable한 피쳐를 뱉지만 높아질 수록 점점 데이터에 맞춰진 feature를 뱉는다.\n",
    "\n",
    "xception은 선박 데이터로 학습된 것이 아니기 떄문에 fine tuning할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBRXeoILKBC7"
   },
   "outputs": [],
   "source": [
    "# Instantiating the VGG16 convolutional base\n",
    "from tensorflow.keras.applications import xception\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "import tensorflow as tf\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "#tf.keras.backend.set_floatx('float32')\n",
    "def get_model(bn_momentum=0.50):\n",
    "    \"\"\"Builds a Sequential CNN model to recognize MNIST.\n",
    "\n",
    "    Args:\n",
    "      input_shape: Shape of the input depending on the `image_data_format`.\n",
    "      dropout2_rate: float between 0 and 1. Fraction of the input units to drop for `dropout_2` layer.\n",
    "\n",
    "    Returns:\n",
    "      a Keras model\n",
    "\n",
    "    \"\"\"\n",
    "    # Reset the tensorflow backend session.\n",
    "    # tf.keras.backend.clear_session()\n",
    "    # Define a CNN model to recognize MNIST.\n",
    "    model = Sequential()\n",
    "    \n",
    "    conv_base = xception.Xception(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    # Freezing all layers up to a specific one\n",
    "    conv_base.trainable = True\n",
    "    set_trainable = False\n",
    "    for layer in conv_base.layers:\n",
    "        if layer.name == 'block14_sepconv2_bn':\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    # momentum optimize using BO\n",
    "    conv_base.layers[-2].momentum = bn_momentum\n",
    "    \n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iILgC52KBC9"
   },
   "outputs": [],
   "source": [
    "def fit_with(bn_momentum, lr):\n",
    "    verbose = 1\n",
    "    \n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = get_model(bn_momentum)\n",
    "\n",
    "    # Train the model for a specified number of epochs.\n",
    "    optimizer = rmsprop.RMSProp(learning_rate=lr)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the train dataset.\n",
    "    model.fit(x=train_generator, epochs=100, steps_per_epoch=100, verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(validation_generator, steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]\n",
    "\n",
    "# from functools import partial\n",
    "\n",
    "# verbose = 1\n",
    "# fit_with_partial = partial(fit_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5433444,
     "status": "error",
     "timestamp": 1575474547484,
     "user": {
      "displayName": "JaeHyun Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA1pE8sVsuuLMGC6ajwh6T9omE5mslxbxmoUVUX=s64",
      "userId": "15717303300889025519"
     },
     "user_tz": -540
    },
    "id": "p2b-00WBKBC_",
    "outputId": "19dd0ede-0dba-42b8-e567-8be2629af6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 199s 2s/step - loss: 4.4765 - acc: 0.4812\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.0984 - acc: 0.6424\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.7553 - acc: 0.7438\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.5672 - acc: 0.8031\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.4323 - acc: 0.8466\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.3808 - acc: 0.8809\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2115 - acc: 0.9315\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2576 - acc: 0.9401\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.1485 - acc: 0.9524\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1437 - acc: 0.9623\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1428 - acc: 0.9646\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0967 - acc: 0.9737\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0976 - acc: 0.9717\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1018 - acc: 0.9789\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0999 - acc: 0.9779\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0825 - acc: 0.9778\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1294 - acc: 0.9776\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0487 - acc: 0.9872\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0677 - acc: 0.9837\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0954 - acc: 0.9803\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0501 - acc: 0.9875\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0660 - acc: 0.9861\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0681 - acc: 0.9851\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0495 - acc: 0.9903\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0486 - acc: 0.9908\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0476 - acc: 0.9892\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0488 - acc: 0.9903\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0709 - acc: 0.9869\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0507 - acc: 0.9876\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0414 - acc: 0.9903\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0547 - acc: 0.9891\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0590 - acc: 0.9903\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0571 - acc: 0.9905\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.1129 - acc: 0.9875\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0801 - acc: 0.9881\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0333 - acc: 0.9936\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0251 - acc: 0.9947\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0567 - acc: 0.9890\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0293 - acc: 0.9934\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0385 - acc: 0.9914\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0564 - acc: 0.9919\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0638 - acc: 0.9894\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0413 - acc: 0.9930\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0598 - acc: 0.9908\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0409 - acc: 0.9941\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0283 - acc: 0.9937\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0307 - acc: 0.9948\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0434 - acc: 0.9944\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0308 - acc: 0.9956\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0425 - acc: 0.9930\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0221 - acc: 0.9950\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0328 - acc: 0.9948\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0196 - acc: 0.9969\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0243 - acc: 0.9966\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0231 - acc: 0.9959\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0275 - acc: 0.9955\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0390 - acc: 0.9936\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0190 - acc: 0.9955\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0180 - acc: 0.9967\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0452 - acc: 0.9928\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0359 - acc: 0.9945\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0150 - acc: 0.9977\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0182 - acc: 0.9961\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0582 - acc: 0.9947\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0391 - acc: 0.9936\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0430 - acc: 0.9939\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0153 - acc: 0.9956\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0316 - acc: 0.9961\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0155 - acc: 0.9970\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0365 - acc: 0.9951\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0182 - acc: 0.9970\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0180 - acc: 0.9967\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0243 - acc: 0.9959\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0251 - acc: 0.9955\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.0310 - acc: 0.9958\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0260 - acc: 0.9959\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0252 - acc: 0.9952\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0282 - acc: 0.9959\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0305 - acc: 0.9962\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0385 - acc: 0.9948\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0332 - acc: 0.9959\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0143 - acc: 0.9981\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0140 - acc: 0.9977\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0306 - acc: 0.9958\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0278 - acc: 0.9973\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0189 - acc: 0.9967\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0259 - acc: 0.9958\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0062 - acc: 0.9983\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0186 - acc: 0.9977\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.0354 - acc: 0.9955\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0184 - acc: 0.9973\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0265 - acc: 0.9953\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0231 - acc: 0.9970\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.0097 - acc: 0.9981\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0135 - acc: 0.9978\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0140 - acc: 0.9978\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0268 - acc: 0.9964\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0275 - acc: 0.9950\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0069 - acc: 0.9987\n",
      "Test loss: 34.200843238830565\n",
      "Test accuracy: 0.5875\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 22.7858 - acc: 0.3512\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 1.7219 - acc: 0.4755\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 1.1248 - acc: 0.6250\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.7994 - acc: 0.7211\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.6999 - acc: 0.7635\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.7279 - acc: 0.8050\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.5393 - acc: 0.8427\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.5208 - acc: 0.8649\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.4778 - acc: 0.8645\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.3515 - acc: 0.8968\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.4061 - acc: 0.8944\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.4192 - acc: 0.9038\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.3223 - acc: 0.9167\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.3098 - acc: 0.9220\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2920 - acc: 0.9282\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.4015 - acc: 0.9272\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.4340 - acc: 0.9358\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.2550 - acc: 0.9485\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.2631 - acc: 0.9486\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.5040 - acc: 0.9478\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.3533 - acc: 0.9486\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.3057 - acc: 0.9507\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2475 - acc: 0.9595\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2592 - acc: 0.9604\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2122 - acc: 0.9620\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.2569 - acc: 0.9662\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.4914 - acc: 0.9538\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2186 - acc: 0.9698\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.2013 - acc: 0.9670\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.3247 - acc: 0.9662\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2984 - acc: 0.9651\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.3246 - acc: 0.9670\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2272 - acc: 0.9748\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.1949 - acc: 0.9784\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.2175 - acc: 0.9706\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2749 - acc: 0.9712\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.2398 - acc: 0.9750\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.3731 - acc: 0.9693\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2046 - acc: 0.9773\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1828 - acc: 0.9814\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1523 - acc: 0.9800\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2248 - acc: 0.9778\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1235 - acc: 0.9842\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1729 - acc: 0.9775\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.1570 - acc: 0.9765\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1317 - acc: 0.9820\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1959 - acc: 0.9782\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2803 - acc: 0.9789\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1993 - acc: 0.9809\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2042 - acc: 0.9814\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1177 - acc: 0.9870\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1944 - acc: 0.9797\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1796 - acc: 0.9804\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1882 - acc: 0.9809\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.2138 - acc: 0.9790\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1285 - acc: 0.9853\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.2123 - acc: 0.9784\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1504 - acc: 0.9806\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2175 - acc: 0.9820\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1932 - acc: 0.9823\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.3080 - acc: 0.9808\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1872 - acc: 0.9853\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2407 - acc: 0.9811\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1920 - acc: 0.9856\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.2087 - acc: 0.9850\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.2476 - acc: 0.9833\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1376 - acc: 0.9862\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1432 - acc: 0.9854\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2800 - acc: 0.9828\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1819 - acc: 0.9811\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2549 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.1541 - acc: 0.9858\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1116 - acc: 0.9872\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.2133 - acc: 0.9840\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.1221 - acc: 0.9872\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.2002 - acc: 0.9853\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2602 - acc: 0.9817\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.1865 - acc: 0.9825\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1694 - acc: 0.9861\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.2278 - acc: 0.9859\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1175 - acc: 0.9873\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2054 - acc: 0.9836\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2195 - acc: 0.9847\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2044 - acc: 0.9865\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1885 - acc: 0.9864\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2137 - acc: 0.9829\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.1070 - acc: 0.9898\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2232 - acc: 0.9836\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.1281 - acc: 0.9887\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.0807 - acc: 0.9895\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.1801 - acc: 0.9862\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1527 - acc: 0.9870\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1896 - acc: 0.9884\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0985 - acc: 0.9912\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.2517 - acc: 0.9850\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1658 - acc: 0.9879\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2897 - acc: 0.9880\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1332 - acc: 0.9909\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1597 - acc: 0.9892\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.2677 - acc: 0.9826\n",
      "Test loss: 2.6790788412094115\n",
      "Test accuracy: 0.1921875\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 7.5886 - acc: 0.4721\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 1.1471 - acc: 0.6402\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.8655 - acc: 0.7281\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.7151 - acc: 0.7792\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.5296 - acc: 0.8498\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.4503 - acc: 0.8820\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2716 - acc: 0.9180\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1866 - acc: 0.9448\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.2621 - acc: 0.9346\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1447 - acc: 0.9593\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1723 - acc: 0.9574\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.1512 - acc: 0.9665\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1101 - acc: 0.9748\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1285 - acc: 0.9745\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.1170 - acc: 0.9806\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.1436 - acc: 0.9737\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0846 - acc: 0.9851\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0804 - acc: 0.9840\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0549 - acc: 0.9856\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1229 - acc: 0.9793\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0742 - acc: 0.9822\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0653 - acc: 0.9884\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0812 - acc: 0.9869\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0661 - acc: 0.9894\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0715 - acc: 0.9866\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0559 - acc: 0.9876\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0378 - acc: 0.9925\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0543 - acc: 0.9894\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0582 - acc: 0.9895\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0888 - acc: 0.9870\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.0552 - acc: 0.9906\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0800 - acc: 0.9869\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0685 - acc: 0.9898\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0859 - acc: 0.9870\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0388 - acc: 0.9923\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0894 - acc: 0.9884\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0726 - acc: 0.9909\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0775 - acc: 0.9886\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0298 - acc: 0.9936\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0466 - acc: 0.9930\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0409 - acc: 0.9934\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0348 - acc: 0.9945\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0537 - acc: 0.9908\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0649 - acc: 0.9901\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0403 - acc: 0.9945\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0380 - acc: 0.9937\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0733 - acc: 0.9922\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0438 - acc: 0.9939\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0555 - acc: 0.9926\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0354 - acc: 0.9931\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0576 - acc: 0.9922\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0598 - acc: 0.9914\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0472 - acc: 0.9942\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0205 - acc: 0.9969\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0553 - acc: 0.9923\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0431 - acc: 0.9950\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0374 - acc: 0.9939\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0467 - acc: 0.9940\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0650 - acc: 0.9931\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0479 - acc: 0.9925\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0523 - acc: 0.9941\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0299 - acc: 0.9945\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0260 - acc: 0.9959\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0325 - acc: 0.9956\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0307 - acc: 0.9961\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0154 - acc: 0.9970\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0413 - acc: 0.9941\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0305 - acc: 0.9958\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0507 - acc: 0.9947\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0694 - acc: 0.9939\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0803 - acc: 0.9928\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0435 - acc: 0.9953\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0652 - acc: 0.9934\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0343 - acc: 0.9953\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0363 - acc: 0.9950\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0477 - acc: 0.9941\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0225 - acc: 0.9967\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0142 - acc: 0.9980\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0456 - acc: 0.9937\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0202 - acc: 0.9980\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0989 - acc: 0.9920\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0525 - acc: 0.9944\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0735 - acc: 0.9931\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0180 - acc: 0.9969\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0506 - acc: 0.9953\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0499 - acc: 0.9950\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0217 - acc: 0.9980\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0656 - acc: 0.9944\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0241 - acc: 0.9967\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0166 - acc: 0.9980\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0701 - acc: 0.9956\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0257 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0500 - acc: 0.9944\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0282 - acc: 0.9973\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.0431 - acc: 0.9969\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0277 - acc: 0.9967\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.0223 - acc: 0.9975\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0233 - acc: 0.9967\n",
      "Test loss: 41.72362937927246\n",
      "Test accuracy: 0.5515625\n",
      "init   \t [0.90480987 0.00167097]. \t  0.5874999761581421 \t 0.5874999761581421\n",
      "init   \t [1.17217046 0.00921506]. \t  0.19218750298023224 \t 0.5874999761581421\n",
      "init   \t [0.87652892 0.0025931 ]. \t  0.551562488079071 \t 0.5874999761581421\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f12c74243143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgpgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPGO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgpgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyGPGO/GPGO.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, max_iter, init_evals, resume)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizeAcq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_printCurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyGPGO/GPGO.py\u001b[0m in \u001b[0;36mupdateGP\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[1;32m    148\u001b[0m         \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-96a0c6109914>\u001b[0m in \u001b[0;36mfit_with\u001b[0;34m(bn_momentum, lr)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Create the model using a specified hyperparameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_momentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Train the model for a specified number of epochs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b3ff6d570c41>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(bn_momentum)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mconv_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    529\u001b[0m       momentum = tf_utils.smart_cond(training,\n\u001b[1;32m    530\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                                      lambda: 1.0)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[0;32m---> 59\u001b[0;31m                                  name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         raise ValueError(\n\u001b[1;32m   1273\u001b[0m             \u001b[0;34m\"Outputs of true_fn and false_fn must have the same type: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \"%s, %s\" % (x.dtype.name, y.dtype.name))\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_f_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Outputs of true_fn and false_fn must have the same type: float64, float32"
     ]
    }
   ],
   "source": [
    "from pyGPGO.covfunc import matern32\n",
    "from pyGPGO.acquisition import Acquisition\n",
    "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
    "from pyGPGO.GPGO import GPGO\n",
    "\n",
    "cov = matern32()\n",
    "gp = GaussianProcess(cov)\n",
    "acq = Acquisition(mode='ExpectedImprovement')\n",
    "param = {'bn_momentum': ('cont', [0.8, 1.2]), 'lr': ('cont', [0.0001, 0.01])}\n",
    "\n",
    "np.random.seed(1337)\n",
    "gpgo = GPGO(gp, acq, fit_with, param, n_jobs=1)\n",
    "gpgo.run(max_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-34wIB01KBDI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlWWNuUWKBDK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IJ4-UntKBDL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BayesianOptimization1205.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
